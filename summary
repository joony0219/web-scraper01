순서요약
1) 모듈설치
2) 가져올 페이지의 url요청 (get .text)
3) 원하는 html 파트 가져오기 (Beautiful Soup)
4) pagination 찾기
5-1) pagination 안의 모든 앵커 찾기
5-2) loop를 이용해 각 페이지의 "span" 모두 찾기
6) 불러올 페이지 넘버 지정해주기

#1. Import Packages (모듈설치)
-영상에서 쓰인 모듈 :
ㄴRequest (사이트 정보 가져오기 (text))
ㄴBeautiful Soup (html 내 필요한 부분 추출하기 (html))

#2. 가져올 페이지의 url요청 (request.get)
-페이지.text 가져왕

#3. 원하는 html 파트 가져오기 (Beautiful Soup)
-위 .text에서 HTML 불러왕 (html.parser)

#4. HTML 내에서 내가 원하는 정보의 pagination(페이지 네비게이터)을 찾기(indeed_soup.find)
ㄴ"div" 를 찾아서 "pagination" 클래스 불러와줭

#5-1. pagination 안의 모든 앵커('a href' 형태로 되어있는 링크들) 찾아주기
ㄴpagination.find_all('a'))

#5-2. 페이지 링크마다 있는 태그를 각각 모두 불러와줘야 하므로 loop(for-in) 사용
ㄴfor link in links: pages.append(link.find("span"))


#6. 어디서부터 어디까지 불러올건지 페이지 넘버 지정해주기
ㄴpages = pages[0:-1]



# 참고

1. 모든 a 태그 검색
soup.find_all("a")
soup("a")

2. string 이 있는 title 태그 모두 검색
soup.title.find_all(string=True)
soup.title(string=True)

3. a 태그를 두개만 가져옴
soup.find_all("a", limit=2)

4. string 검색
soup.find_all(string="Elsie") # string 이 Elsie 인 것 찾기
soup.find_all(string=["Tillie", "Elsie", "Lacie"]) # or 검색
soup.find_all(string=re.compile("Dormouse")) # 정규식 이용

5. p 태그와 속성 값이 title 이 있는거
soup.find_all("p", "title")
예)

6. a태그와 b태그 찾기
soup.find_all(["a", "b"])

7. 속성 값 가져오기
soup.p['class']
soup.p['id']

8. string을 다른 string으로 교체
tag.string.replace_with("새로운 값")

9. 보기 좋게 출력
soup.b.prettify()

10. 간단한 검색
soup.body.b # body 태그 아래의 첫번째 b 태그
soup.a # 첫번째 a 태그

11. 속성 값 모두 출력
tag.attrs

12. class 는 파이썬에서 예약어이므로 class_ 로 쓴다.
soup.find_all("a", class_="sister")

13. find
find()
find_next()
find_all()

14. find 할 때 확인
if soup.find("div", title=True) is not None:
i = soup.find("div", title=True)

15. data-로 시작하는 속성 find
soup.find("div", attrs={"data-value": True})

16. 태그명 얻기
soup.find("div").name

17. 속성 얻기
soup.find("div")['class'] # 만약 속성 값이 없다면 에러
soup.find("div").get('class') # 속성 값이 없다면 None 반환

18. 속성이 있는지 확인
tag.has_attr('class')
tag.has_attr('id')
있으면 True, 없으면 False

19. 태그 삭제
a_tag.img.unwrap()

20. 태그 추가
soup.p.string.wrap(soup.new_tag("b"))
soup.p.wrap(soup.new_tag("div")
